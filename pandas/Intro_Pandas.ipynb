{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![NASA](http://www.nasa.gov/sites/all/themes/custom/nasatwo/images/nasa-logo.svg)\n",
    "\n",
    "<center><h1><font size=\"+3\">GSFC Introductory Python Training</font></h1></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](img/pandas_logo.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`pandas` is an open source, BSD-licensed library providing high-performance, easy-to-use data structures and data analysis tools for the Python programming language."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>Reference: http://pandas.pydata.org</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Topics:\n",
    "    1. Pandas data structures\n",
    "    2. Loading data\n",
    "    3. Cleaning and formatting data\n",
    "    4. Basic visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standard imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The <font color='red'>Pandas</font> library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "print('Using pandas version ',pd.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Notebook settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "pd.set_option(\"max_rows\", 10) # only 10 rows of data will be displayed\n",
    "np.set_printoptions(suppress=True)\n",
    "LARGE_FIGSIZE = (8, 6) # set figure size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Graphics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from seaborn import set_style\n",
    "#set_style(\"darkgrid\")\n",
    "import seaborn as sns\n",
    "sns.set(style='ticks', context='talk')\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center>Motivation</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dict = { \n",
    "     'name' : [\"John\", \"Diane\", \"Joe\", \"Danielle\", \"Ashley\", \"Sam\"],\n",
    "     'age' : [20,55, 35, 40, 21, 35],\n",
    "     'salary' : [41000,73000, 68000, 65000, 50000, 55000],\n",
    "     'designation': [\"VP\", \"CEO\", \"CFO\", \"VP\", \"VP\", \"VP\"]\n",
    "}\n",
    "my_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But what if you want to get the designation for Employee Sam? There are several ways to do this, but most are not clean and straightforward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "B = np.reshape(np.arange(9),(3,3))\n",
    "B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "B[0][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But what if you want to get the to access data via indexing other than index location? There are several ways to do this, but most are not clean and straightforward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use **Pandas** for this. Pandas has two basic data structures:\n",
    "* **Series**, which are one-dimensional labeled arrays, resembling dictionaries\n",
    "* **DataFrame** (most commonly used) is 2-dimensional, like a spreadsheet, or a dictionary of Series "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center>Pandas data structures</center>\n",
    "\n",
    "<center>Pandas data structures are similar to numpy ndarrays but with extra functionality.</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1D data structures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A <font color='red'>Series</font>  is a one-dimensional labeled array capable of holding any data type (integers, strings, floating point numbers, Python objects, etc.). The axis labels are collectively referred to as the index. \n",
    "\n",
    "Think of a Series as a cross between a list and a dict."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](img/pandas_series.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A series can be constructed with the `pd.Series` constructor (passing a list or array of values)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([5, 8, 13, 0.1, -5])   # Numpy\n",
    "print(type(a))\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pd.Series([5, 8, 13, 0.1, -5]) # Pandas\n",
    "print(type(s))\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...get default index values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NumPy arrays as backend of Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.values  # Contains an array of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "s.index # has an associated array of data labels from 0, N-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### More on the index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pd.Series([5, 8, 13, 0.1, -5],\n",
    "        index=['A','B','C','D','E'])\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Numpy Array has an implicitly defined integer index used to access the values while the Pandas Series has an explicitly defined index associated with the values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(s[3])  # value at position 0 in series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(s.iloc[3]) # use iloc to get value at position n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(s.loc['D']) # value at given index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### index and position are not the same !!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2D data structures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas: <font color='red'>DataFrame</font> is a 2-dimensional labeled data structure with columns of potentially different types. It is generally the most commonly used pandas object.\n",
    "\n",
    "A <font color='red'>DataFrame</font> is like a sequence of aligned <font color='red'>Series</font> objects, i.e. they share the same index."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](img/pandas_df.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A DataFrame can be thought of as a generalization of a two-dimensional NumPy array, where both the rows and columns have a generalized index for accessing the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(\n",
    "    data=[[5, True, 'x', 2.7],\n",
    "          [8, True, 'y', 3.1],\n",
    "          [13,False,'z',np.NaN],\n",
    "          [1, False, 'a', 0.1],\n",
    "          [-5, True, 'b', -2]],\n",
    "    index=['A','B','C','D','E'],\n",
    "    columns=['num', 'bool', 'str', 'real']\n",
    ")\n",
    "print(type(df))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a DataFrame from a 2D Numpy array\n",
    "\n",
    "Given a two-dimensional array of data, we can create a dataframe with any specified column and index names. If left out, an integer index will be used for each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.rand(3, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(np.random.rand(3, 2),\n",
    "             columns=['foo', 'bar'],\n",
    "             index=['a', 'b', 'c'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "Use the dictionary created earlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dict = { \n",
    "     'name' : [\"John\", \"Diane\", \"Joe\", \"Danielle\", \"Ashley\", \"Sam\"],\n",
    "     'age' : [20,55, 35, 40, 21, 35],\n",
    "     'salary' : [41000,73000, 68000, 65000, 50000, 55000],\n",
    "     'designation': [\"VP\", \"CEO\", \"CFO\", \"VP\", \"VP\", \"VP\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Create a dataframe named __employees__\n",
    "* Set the index to be the __name__ key\n",
    "* Print the designation of employee __Sam__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "employees = pd.DataFrame(my_dict)\n",
    "employees.set_index('name', inplace=True)\n",
    "employees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Furthermore:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(B)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accessing data vs Numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center>Climate data</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <center>Global Surface Temperature Change based on Land and Ocean Data</center>\n",
    "<center>Reference http://pubs.giss.nasa.gov/docs/2010/2010_Hansen_ha00510u.pdf</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!head data/climate/annual.land_ocean.90S.90N.df_1880-2016mean.dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "!tail data/climate/annual.land_ocean.90S.90N.df_1880-2016mean.dat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pandas <font color='red'>read_csv</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"data/climate/annual.land_ocean.90S.90N.df_1880-2016mean.dat\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsurf = pd.read_csv(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Data type:',type(tsurf))\n",
    "print('Data:\\n')\n",
    "print(tsurf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is only 1 column! Let's reformat the data noting that there is a header and values are separated by any number of spaces."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data wrangling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tsurf = pd.read_csv(filename, skiprows=5, sep=\"\\s+\")\n",
    "tsurf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are columns but the column names are: 1880, -0.20, -0.13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsurf = pd.read_csv(filename, skiprows=5, sep=\"\\s+\", names=[\"year\", \"mean_anom\", \"with_smoothing\"])\n",
    "tsurf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We only have 3 columns, one of which one of which is the year of the record. Let use that as the index using the `index_col` option:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsurf = pd.read_csv(filename, skiprows=5, sep=\"\\s+\", names=[\"year\", \"mean_anom\", \"with_smoothing\"], \n",
    "                                index_col=0)\n",
    "tsurf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's look at the index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But the index is made of dates. Let's make that explicit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsurf = pd.read_csv(filename, skiprows=5, sep=\"\\s+\", names=[\"year\", \"mean_anom\", \"with_smoothing\"], \n",
    "                                index_col=0, parse_dates=True)  # parse_dates -> DatetimeIndexes\n",
    "tsurf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tsurf.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsurf.index[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dealing with missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsurf.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to missing values to NaN values\n",
    "tsurf[tsurf == -999.000] = np.nan\n",
    "tsurf.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Remove NaN values\n",
    "tsurf = tsurf.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tsurf.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = tsurf.mean_anom.plot(style=\"black\", \n",
    "                          title=\"Global Mean Estimates based on Land and Ocean Data\", \n",
    "                          marker='s',\n",
    "                          figsize=(12,6))\n",
    "tsurf.with_smoothing.plot(style=\"red\", ax=ax)\n",
    "ax.set_ylabel(\"Temperature Anomaly(C)\")\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = 'https://data.giss.nasa.gov/gistemp/graphs/graph_data/Global_Mean_Estimates_based_on_Land_and_Ocean_Data/graph.png'\n",
    "from IPython.display import Image\n",
    "Image(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center>Solar data</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>http://heliophysics.com/documents/TSI%20and%20Fuv%20using%20Apn%202012%20and%20Af%202015.xlsx</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls data/solar/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reading Excel files requires the xlrd library. You can install it via pip or conda."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solar_data_xls = \"data/solar/TSI and Fuv using Apn 2012 and Af 2015.xlsx\" # Needs xlrd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(solar_data_xls)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!head data/solar/tsi_fuv.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solar_data = \"data/solar/tsi_fuv.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solar = pd.read_csv(solar_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "solar = pd.read_csv(solar_data, index_col=0, names=[\"year\", \"tsi\", \"tsi2\", \"fuv\"], parse_dates=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solar.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solar[\"tsi\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solar.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rename columns\n",
    "\n",
    "Assign a new list of column names to the columns property of the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solar.columns = [\"TSI_WL\", \"TSI_Ca_K\", \"solar_uv_irradiance_variation\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "solar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solar.columns = [\"tsi\", \"tsi2\", \"fuv\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, we can use . dot \n",
    "solar.fuv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solar.tsi.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "solar.tsi.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=2, ncols=1, figsize=(12,6))\n",
    "ax[0].plot(solar.tsi,'b', solar.tsi2,'g')\n",
    "ax[1].plot(solar.fuv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "solar[['tsi','tsi2','fuv']].plot(subplots=True, figsize=(16, 12));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The <font color='red'>plot()</font> function returns a matplotlib <font color='red'>AxesSubPlot</font> object. You can pass this object into subsequent calls to plot() in order to compose plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from pandas.plotting import scatter_matrix\n",
    "scatter_matrix(solar);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.plotting import scatter_matrix\n",
    "scatter_matrix(solar, alpha=0.2, figsize=(10, 10), diagonal='kde');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(style=\"ticks\")\n",
    "sns.pairplot(solar, diag_kind='kde');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center>Sea level dataset</center>\n",
    "\n",
    "The __University of Colorado__ posts updated timeseries for mean sea level globally, per hemisphere, and even per ocean, sea.\n",
    "\n",
    "In this example we will download the global one, and the ones for the northern and southern hemisphere.\n",
    "\n",
    "That will also illustrate that to load text files that are online, there is no more work than replacing the filepath by a URL in `read_csv`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "northern_sea_level = pd.read_csv(\"http://sealevel.colorado.edu/files/current/sl_nh.txt\", \n",
    "                                   sep=\"\\s+\")\n",
    "print(type(northern_sea_level))\n",
    "northern_sea_level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "southern_sea_level = pd.read_csv(\"http://sealevel.colorado.edu/files/current/sl_sh.txt\", \n",
    "                                   sep=\"\\s+\")\n",
    "southern_sea_level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The 2016 version of the global dataset:\n",
    "url = \"http://sealevel.colorado.edu/files/2016_rel2/sl_ns_global.txt\"\n",
    "global_sea_level = pd.read_csv(url, sep=\"\\s+\")\n",
    "global_sea_level"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating new DataFrames\n",
    "\n",
    "New `DataFrame`s can  be created manually by grouping several Series together. \n",
    "\n",
    "Let's make a new frame from the 3 sea level datasets so that they can be displayed along the same index. \n",
    "\n",
    "Wait, does it make sense to do that?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For two Series to share the same DataFrame the Series have to be aligned.\n",
    "# Let's look at sea level data for NH and SH. Are they aligned?\n",
    "southern_sea_level.year == northern_sea_level.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Could use Numpy:\n",
    "np.all(southern_sea_level.year == northern_sea_level.year)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the northern hemisphere and southern hemisphere datasets are aligned. What about the global one?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(global_sea_level.year))\n",
    "print(len(northern_sea_level.year))\n",
    "len(global_sea_level.year) == len(northern_sea_level.year)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For now, let's just build a DataFrame with the 2 hemisphere datasets then. We will come back to add the global one later..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A dictionary of Series\n",
    "mean_sea_level = pd.DataFrame({\"northern_hem\": northern_sea_level[\"msl_ib(mm)\"], \n",
    "                               \"southern_hem\": southern_sea_level[\"msl_ib(mm)\"], \n",
    "                               \"date\": northern_sea_level.year})\n",
    "mean_sea_level"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is still the date in a regular column and a numerical index that is not that meaningful (or useful). We can specify the `index` of a `DataFrame` at creation. Let's try:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_sea_level = pd.DataFrame({\"northern_hem\": northern_sea_level[\"msl_ib(mm)\"], \n",
    "                               \"southern_hem\": southern_sea_level[\"msl_ib(mm)\"]},\n",
    "                               index = northern_sea_level.year)\n",
    "mean_sea_level"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What's going on?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note that\n",
    "northern_sea_level[\"msl_ib(mm)\"].index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is no `value` corresponding to the Series' `index`.\n",
    "\n",
    "But there is `value` corresponding to the specified `index`.\n",
    "\n",
    "So, replace the Series by their values when creating the DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mean_sea_level = pd.DataFrame({\"northern_hem\": northern_sea_level[\"msl_ib(mm)\"].values, \n",
    "                               \"southern_hem\": southern_sea_level[\"msl_ib(mm)\"].values},\n",
    "                               index = northern_sea_level.year)\n",
    "mean_sea_level"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note the following:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Index name, `year`, is not an accurate description of what it indexes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can rename an index by setting its name. \n",
    "\n",
    "For example, the index of the `mean_sea_level` dataFrame could be called `date` since it contains more than just the year:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_sea_level.index.name = \"date\"\n",
    "mean_sea_level"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While building the `mean_sea_level` dataFrame earlier, we didn't include the values from `global_sea_level` since the years were not aligned. \n",
    "\n",
    "Adding a column to a dataframe is as easy as adding an entry to a dictionary. So let's try:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_sea_level[\"mean_global\"] = global_sea_level[\"msl_ib_ns(mm)\"]\n",
    "mean_sea_level"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The column is full of NaNs again because the auto-alignment feature of Pandas is searching for the index values like `1992.9323` in the index of `global_sea_level[\"msl_ib_ns(mm)\"]` series and not finding them. Let's set its index to these years so that that auto-alignment can work for us and figure out which values we have and not:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_sea_level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_sea_level = global_sea_level.set_index(\"year\")\n",
    "global_sea_level[\"msl_ib_ns(mm)\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mean_sea_level[\"mean_global\"] = global_sea_level[\"msl_ib_ns(mm)\"]\n",
    "mean_sea_level.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.option_context(\"max_rows\", 40):\n",
    "    print(mean_sea_level.fillna(value=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_sea_level.plot(subplots=True, figsize=(16, 12));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are more plot options inside `pandas.tools.plotting`; for example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_sea_level.plot(kind='kde', figsize=(12, 8));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Are there correlations between the northern and southern sea level timeseries we loaded?\n",
    "from pandas.plotting import scatter_matrix\n",
    "scatter_matrix(mean_sea_level, figsize=LARGE_FIGSIZE);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center>Web scraping sea level data</center>\n",
    "\n",
    "There is more data about mean sea levels. For example, the PSMSL website (http://www.psmsl.org/) contains MSL data from stations around the world. Here we download and parse all tables in a webpage, and again we just give `read_html` the URL to parse:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pandas  <font color='red'>read_html</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Needs `lxml`, `beautifulSoup4` and `html5lib` python packages\n",
    "table_list = pd.read_html(\"http://www.psmsl.org/data/obtaining/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(table_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_list[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# there is 1 table on that page which contains metadata about the stations where \n",
    "# sea levels are recorded\n",
    "local_sea_level_stations = table_list[0]\n",
    "local_sea_level_stations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That table can be used to search for a station in a region of the world we choose, extract an ID for it and download the corresponding time series with the URL http://www.psmsl.org/data/obtaining/met.monthly.data/< ID >.metdata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The datasets that we obtain straight from the reading functions are pretty raw. A lot of pre-processing can be done during data read but we haven't used all the power of the reading functions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The columns of the local_sea_level_stations aren't clean: they contain spaces and dots.\n",
    "local_sea_level_stations.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's clean them up a bit:\n",
    "local_sea_level_stations.columns = [name.strip().replace(\".\", \"\") \n",
    "                                    for name in local_sea_level_stations.columns]\n",
    "local_sea_level_stations.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_sea_level_stations"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
